{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"4rhcNP-5SKt4"},"outputs":[],"source":["from pydrive.auth import GoogleAuth\n","from pydrive.drive import GoogleDrive\n","from google.colab import auth\n","from oauth2client.client import GoogleCredentials\n","\n","auth.authenticate_user()\n","gauth = GoogleAuth()\n","gauth.credentials = GoogleCredentials.get_application_default()\n","drive = GoogleDrive(gauth)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":29602,"status":"ok","timestamp":1613314077568,"user":{"displayName":"Mir Tanvir","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgJpOSXXlrw46YM-e8ALEVX-a_cx21d04dSS91jz0s=s64","userId":"11357466866423763078"},"user_tz":-360},"id":"GRvqSSun7a0e","outputId":"08568d1f-fec5-4f0b-ba95-81d460d0deca"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0XpcTWV9YvmR"},"outputs":[],"source":["!unzip -qq '/content/drive/My Drive/Colab Notebooks/Glaucoma detection/Data/BEH.zip'"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12160,"status":"ok","timestamp":1613314177979,"user":{"displayName":"Mir Tanvir","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgJpOSXXlrw46YM-e8ALEVX-a_cx21d04dSS91jz0s=s64","userId":"11357466866423763078"},"user_tz":-360},"id":"sm-isgSaSrq-","outputId":"d6eaaff6-a046-4a1d-b3f4-639b6a46d9c3"},"outputs":[],"source":["!pip install git+https://github.com/karolzak/keras-unet\n","\n","import numpy as np\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","import glob\n","import os\n","import sys\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","import torchvision\n","import torchvision.models as models\n","from torchvision.utils import make_grid\n","from torch.utils.data import Dataset, random_split, DataLoader\n","import torchvision.transforms as transforms\n","import torchvision.transforms.functional as TF\n","import random\n","from torchvision.utils import make_grid\n","from PIL import Image\n","from keras_unet.utils import plot_imgs\n","from sklearn.model_selection import train_test_split\n","from keras_unet.models import custom_unet\n","from keras.callbacks import ModelCheckpoint\n","from keras.optimizers import Adam, SGD\n","from keras_unet.metrics import iou, iou_thresholded\n","from keras_unet.losses import jaccard_distance\n","from keras_unet.utils import plot_imgs, plot_segm_history"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7491,"status":"ok","timestamp":1613314197637,"user":{"displayName":"Mir Tanvir","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgJpOSXXlrw46YM-e8ALEVX-a_cx21d04dSS91jz0s=s64","userId":"11357466866423763078"},"user_tz":-360},"id":"XyeXWiOIWACi","outputId":"f4b081d0-b699-4779-d46e-23399e71b586"},"outputs":[],"source":["# Load FAU dataset\n","\n","orgs = glob.glob(\"/content/FAU/training/original/*\")\n","masks = glob.glob(\"/content/FAU/training/mask/*\")\n","size = 512\n","\n","imgs_list = []\n","masks_list = []\n","for image, mask in zip(orgs, masks):\n","    imgs_list.append(np.array(Image.open(image).resize((size,size)))[:,:,1])\n","    im = Image.open(mask).resize((512,512))\n","    masks_list.append(np.array(im))\n","\n","imgs_np = np.asarray(imgs_list)\n","masks_np = np.asarray(masks_list)\n","\n","print('Original Images:', imgs_np.shape, ' Ground Truth images:', masks_np.shape)\n","# plot_imgs(org_imgs=imgs_np, mask_imgs=masks_np, nm_img_to_plot=10, figsize=6)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZALKq-7ZcTze"},"outputs":[],"source":["dataset_glaucoma = glob.glob(\"/content/BEH/Train/glaucoma/*.jpg\")\n","dataset_normal = glob.glob(\"/content/BEH/Train/normal/*.jpg\")\n","\n","dataset = []\n","for image in dataset_glaucoma:\n","    dataset.append(np.array(Image.open(image).resize((size,size)))[:,:,1])\n","for image in dataset_normal:\n","    dataset.append(np.array(Image.open(image).resize((size,size)))[:,:,1])\n","\n","dataset_np = np.asarray(dataset)\n","dataset_x = np.asarray(dataset_np, dtype=np.float32)/255\n","dataset_x = dataset_x.reshape(dataset_x.shape[0], dataset_x.shape[1], dataset_x.shape[2], 1)\n","print('Dataset:', dataset_x.shape)\n","plot_imgs(org_imgs=dataset_np, mask_imgs=masks_np, nm_img_to_plot=10, figsize=6)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":282},"executionInfo":{"elapsed":1063,"status":"error","timestamp":1603977560012,"user":{"displayName":"Mir Tanvir","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgJpOSXXlrw46YM-e8ALEVX-a_cx21d04dSS91jz0s=s64","userId":"11357466866423763078"},"user_tz":-360},"id":"vFy0n3F1fcG-","outputId":"4ed2b852-ff67-44d6-a386-403c8a9e80d4"},"outputs":[],"source":["# Get data into correct shape, dtype and range (0.0-1.0)\n","print(imgs_np.max(), masks_np.max())\n","x = np.asarray(imgs_np, dtype=np.float32)/255\n","y = np.asarray(masks_np, dtype=np.float32)/255\n","print(x.max(), y.max())\n","print(x.shape, y.shape)\n","y = y.reshape(y.shape[0], y.shape[1], y.shape[2], 1)\n","x = x.reshape(x.shape[0], x.shape[1], x.shape[2], 1)\n","print(x.shape, y.shape)\n","\n","x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.1, random_state=0)\n","\n","print(\"x_train: \", x_train.shape)\n","print(\"y_train: \", y_train.shape)\n","print(\"x_val: \", x_val.shape)\n","print(\"y_val: \", y_val.shape)\n","\n","from keras_unet.utils import get_augmented\n","\n","train_gen = get_augmented(\n","    x_train, y_train, batch_size=8,\n","    data_gen_args = dict(\n","        rotation_range=5.,\n","        width_shift_range=0.05,\n","        height_shift_range=0.05,\n","        shear_range=40,\n","        zoom_range=0.2,\n","        horizontal_flip=True,\n","        vertical_flip=False,\n","        fill_mode='constant'\n","    ))\n","\n","sample_batch = next(train_gen)\n","xx, yy = sample_batch\n","print(xx.shape, yy.shape)\n","from keras_unet.utils import plot_imgs\n","\n","# Plot Dataset and Masks\n","plot_imgs(org_imgs=xx, mask_imgs=yy, nm_img_to_plot=3, figsize=6)\n","\n","# Initialize network\n","input_shape = x_train[0].shape\n","\n","model = custom_unet(\n","    input_shape,\n","    filters=32,\n","    use_batch_norm=True,\n","    dropout=0.3,\n","    dropout_change_per_layer=0.0,\n","    num_layers=4\n",")\n","\n","model_filename = 'segm_model_v3.h5'\n","callback_checkpoint = ModelCheckpoint(\n","    model_filename, \n","    verbose=1, \n","    monitor='val_loss', \n","    save_best_only=True,\n",")\n","\n","model.compile(\n","    optimizer=Adam(), \n","    # optimizer=SGD(lr=0.01, momentum=0.99),\n","    loss='binary_crossentropy',\n","    #loss=jaccard_distance,\n","    metrics=[iou, iou_thresholded]\n",")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":272},"executionInfo":{"elapsed":303890,"status":"ok","timestamp":1602339540184,"user":{"displayName":"Mir Tanvir","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgJpOSXXlrw46YM-e8ALEVX-a_cx21d04dSS91jz0s=s64","userId":"11357466866423763078"},"user_tz":-360},"id":"HSRL64_cg4n0","outputId":"0866065c-5767-47e9-c7e3-4d6e091e75c2"},"outputs":[],"source":["history = model.fit_generator(\n","    train_gen,\n","    steps_per_epoch=200,\n","    epochs=3,\n","    validation_data=(x_val, y_val),\n","    callbacks=[callback_checkpoint]\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hLoTzLhThAbx"},"outputs":[],"source":["plot_segm_history(history)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":17999,"status":"ok","timestamp":1602341590840,"user":{"displayName":"Mir Tanvir","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgJpOSXXlrw46YM-e8ALEVX-a_cx21d04dSS91jz0s=s64","userId":"11357466866423763078"},"user_tz":-360},"id":"BeTt35KEg5uD","outputId":"fe914746-2219-48a1-f0db-d70961c528b9"},"outputs":[],"source":["# Segment Training data\n","model.load_weights(model_filename)\n","y_pred = model.predict(x_val)\n","y_pred = np.moveaxis(y_pred, -1, 1)\n","plot_imgs(org_imgs=x_val, mask_imgs=y_val, pred_imgs=y_pred, nm_img_to_plot=8)\n","\n","# Segment dataset\n","dataset_y_pred = model.predict(dataset_x)\n","plot_imgs(org_imgs=dataset_x, mask_imgs=dataset_y_pred, pred_imgs=dataset_y_pred, nm_img_to_plot=8)\n","dataset_x = np.moveaxis(dataset_x, -1, 1)\n","dataset_y_pred = np.moveaxis(dataset_y_pred, -1, 1)\n","print(dataset_x.shape, dataset_y_pred.shape)\n","\n","import torch\n","x = torch.Tensor(dataset_y_pred)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ArNPeOFJ8gvW"},"outputs":[],"source":["from torchvision.utils import save_image\n","from pathlib import Path\n","\n","for i in range(len(dataset_glaucoma)):\n","    output = x[i][0]\n","    out_dir = Path('/content/ORIGA_af/glaucoma')\n","    out_filename = str(i) + '_BEH.jpg'\n","    output_name = out_dir.joinpath(out_filename)\n","    save_image(output, output_name, padding=0)\n","\n","for i in range(len(dataset_glaucoma), len(x)):\n","    output = x[i][0]\n","    out_dir = Path('/content/ORIGA_af/normal')\n","    out_filename = str(i) + '_BEH.jpg'\n","    output_name = out_dir.joinpath(out_filename)\n","    save_image(output, output_name, padding=0)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":1773,"status":"ok","timestamp":1602342087531,"user":{"displayName":"Mir Tanvir","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgJpOSXXlrw46YM-e8ALEVX-a_cx21d04dSS91jz0s=s64","userId":"11357466866423763078"},"user_tz":-360},"id":"ESi8kmToFZep","outputId":"e73a0649-2c36-40f2-d503-d12a12ef7303"},"outputs":[],"source":["# Zip segmented dataset\n","!zip -r -j BEH '/content/BEH/'"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyN2tuJFhLTQ6mIkZlj9aEs2","collapsed_sections":[],"mount_file_id":"17sRQe9E7poCXKtjRAwT-Iew9GXBXQme5","name":"Copy of Img Segmentation.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}
