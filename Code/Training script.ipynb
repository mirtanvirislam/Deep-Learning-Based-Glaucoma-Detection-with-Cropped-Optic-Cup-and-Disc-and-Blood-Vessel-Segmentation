{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IG5076s0rrGO",
        "outputId": "4937f5b8-4999-41e7-e586-12146340b8b1"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "import os\n",
        "import glob\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sn\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from torchvision.utils import make_grid\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from torch.utils.data import Dataset, random_split, DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.transforms.functional as TF\n",
        "%matplotlib inline\n",
        "%reload_ext tensorboard\n",
        "import random\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from sklearn.metrics import roc_curve, roc_auc_score, precision_recall_curve, f1_score, auc\n",
        "from datetime import datetime\n",
        "from time import time\n",
        "import PIL\n",
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from matplotlib import pyplot\n",
        "!pip install efficientnet_pytorch\n",
        "from efficientnet_pytorch import EfficientNet\n",
        "\n",
        "def show_batch(data_loader, n=8, nrow=4):\n",
        "    for images, labels in data_loader:\n",
        "        fig, ax = plt.subplots(figsize=(12, 12))\n",
        "        ax.set_xticks([]); ax.set_yticks([])\n",
        "        ax.imshow(make_grid(images[:n], nrow=nrow).permute(1, 2, 0))\n",
        "        break\n",
        "\n",
        "def get_num_correct(preds, labels):\n",
        "    return preds.argmax(dim=1).eq(labels).sum().item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4-CznO8Rr2tk"
      },
      "outputs": [],
      "source": [
        "DATASET = 'test1'\n",
        "LEARNING_RATE = 0.001\n",
        "LR_DECAY = 0.96\n",
        "LR_UPDATE_INTERVAL_IN_ITERATIONS = None # initialized later to every epoch, if value is None\n",
        "MODEL_SAVE_INTERVAL_IN_EPOCHS = 1\n",
        "\n",
        "NUM_WORKERS = 1\n",
        "LOG_INTERVAL = None # initialized later to every epoch, if value is None\n",
        "IMG_RECONSTRUCTION_INTERVAL = 500\n",
        "SEED = 1\n",
        "GPU_DEVICE = 0\n",
        "MULTI_GPU = False \n",
        "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "DATA_PATH = 'logs/'\n",
        "G_DRIVE_DIR_BASE = '/content/drive/MyDrive/Colab Notebooks/BEH/'\n",
        "MODEL_DIR_BASE = DATA_PATH + 'models/'\n",
        "TB_RUN_DIR_BASE = DATA_PATH + 'runs/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ELg2HDnar7i1",
        "outputId": "dac1ca51-be46-4a63-8a60-dbdd93a60403"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "r-jQYWFXr9oY",
        "outputId": "10428be4-dcfe-4d8a-f6e5-3bd6180036c7"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "LOG_INTERVAL = None # initialized later to every epoch, if value is None\n",
        "LR_UPDATE_INTERVAL_IN_ITERATIONS = None # initialized later to every epoch, if value is None\n",
        "\n",
        "if DATASET == 'test1':\n",
        "    if not os.path.exists('/content/BEH'):\n",
        "        !unzip -qq '/content/drive/MyDrive/Colab Notebooks/Glaucoma detection/Data/BEH.zip' # link to file on gdrive\n",
        "\n",
        "    EPOCHS = 10\n",
        "    BATCH_SIZE = 6 #13 #16\n",
        "    TRAIN_VAL_RATIO = 0.90\n",
        "    train_data_path = '/content/BEH/train'\n",
        "    validation_data_path = '/content/BEH/validation'\n",
        "    test_data_path = '/content/BEH/test'\n",
        "    classes = ['glaucoma', 'normal']\n",
        "\n",
        "    test_set_filenames = [\n",
        "        sorted([f for f in os.listdir(test_data_path+'/Glaucoma') if os.path.isfile(os.path.join(test_data_path+'/Glaucoma', f))]),\n",
        "        sorted([f for f in os.listdir(test_data_path+'/Normal') if os.path.isfile(os.path.join(test_data_path+'/Normal', f))])\n",
        "    ]\n",
        "\n",
        "    common_transforms = transforms.Compose([\n",
        "        # transforms.Resize((256, 256)),\n",
        "        # #transforms.Grayscale(num_output_channels=3),\n",
        "        # transforms.ToTensor(),\n",
        "        # transforms.Normalize(mean=[0.25, 0.25, 0.25],std=[0.9, 0.9, 0.9])\n",
        "        #transforms.ToPILImage(),\n",
        "        transforms.Resize((300, 300)),\n",
        "        #transforms.CenterCrop((100, 100)),\n",
        "        #transforms.RandomCrop((80, 80)),\n",
        "        # transforms.RandomHorizontalFlip(p=0.5),\n",
        "        # transforms.RandomRotation(degrees=(-90, 90)),\n",
        "        # transforms.RandomVerticalFlip(p=0.5),\n",
        "        transforms.ToTensor(),\n",
        "        # transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "        # transforms.Normalize(mean=[0.25, 0.25, 0.25],std=[0.9, 0.9, 0.9])\n",
        "        transforms.Normalize(mean=[0.05, 0.05, 0.05],std=[0.5, 0.5, 0.5])\n",
        "    ])\n",
        "\n",
        "    train_transforms = transforms.Compose([\n",
        "        #transforms.ColorJitter(brightness=0.15, contrast=0.15, saturation=0.15, hue=0.05),\n",
        "        #transforms.RandomAffine(degrees=(-2,2), translate=None, scale=(0.95, 1.1), shear=0, resample=False, fillcolor=0),\n",
        "        #transforms.CenterCrop((250, 250)),\n",
        "        #transforms.Resize((256, 256)),\n",
        "        # transforms.Resize((300, 300)),\n",
        "        #transforms.CenterCrop((100, 100)),\n",
        "        #transforms.RandomCrop((80, 80)),\n",
        "        # transforms.RandomHorizontalFlip(p=0.5),\n",
        "        # transforms.RandomRotation(degrees=(-90, 90)),\n",
        "        # transforms.RandomVerticalFlip(p=0.5),\n",
        "        # transforms.ColorJitter(brightness=0.1, contrast=0.2, saturation=0, hue=0),\n",
        "        # transforms.ToTensor(),\n",
        "        # #transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "        # transforms.Normalize(mean=[0.25, 0.25, 0.25],std=[0.9, 0.9, 0.9]),\n",
        "        common_transforms\n",
        "    ])\n",
        "\n",
        "    test_transforms = transforms.Compose([\n",
        "        common_transforms\n",
        "    ])\n",
        "else:\n",
        "    raise ValueError('DATASET not specified')\n",
        "\n",
        "TB_COMMENT = f'Network {DATASET} batch_size={BATCH_SIZE} lr={LEARNING_RATE} lr_decay={LR_DECAY} E={EPOCHS}'\n",
        "TB_RUN_DIR = TB_RUN_DIR_BASE + TB_COMMENT\n",
        "MODEL_DIR = MODEL_DIR_BASE + TB_COMMENT\n",
        "G_DRIVE_DIR = G_DRIVE_DIR_BASE + TB_COMMENT\n",
        "print(TB_COMMENT)\n",
        "\n",
        "\n",
        "loaders = {}\n",
        "\n",
        "train_set = torchvision.datasets.ImageFolder(root=train_data_path, transform = train_transforms)\n",
        "loaders['train'] = torch.utils.data.DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)\n",
        "\n",
        "validation_set = torchvision.datasets.ImageFolder(root=validation_data_path, transform = train_transforms)\n",
        "loaders['validation'] = torch.utils.data.DataLoader(validation_set, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)\n",
        "\n",
        "test_set = torchvision.datasets.ImageFolder(root=test_data_path, transform = test_transforms)\n",
        "loaders['test'] = torch.utils.data.DataLoader(test_set, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)\n",
        "\n",
        "\n",
        "if LOG_INTERVAL == None:\n",
        "    LOG_INTERVAL =  len(loaders['train'])\n",
        "\n",
        "print( 8*'#', f'Using {DATASET} dataset', 8*'#')\n",
        "print(\"Train loader. \\tSize: \", len(train_set), '\\tData Shape: ', train_set[0][0].shape, '\\tBatch len: ', len(loaders['train']))\n",
        "print(\"Val loader. \\tSize: \", len(validation_set), '\\tData Shape: ', validation_set[0][0].shape, '\\tBatch len: ', len(loaders['validation']))\n",
        "print(\"Test loader.  \\tSize: \", len(test_set), '\\tData Shape: ', test_set[0][0].shape, '\\tBatch len: ', len(loaders['test']))\n",
        "\n",
        "if LR_UPDATE_INTERVAL_IN_ITERATIONS == None: LR_UPDATE_INTERVAL_IN_ITERATIONS = len(loaders['train'])\n",
        "MODEL_SAVE_INTERVAL_IN_ITERATIONS = MODEL_SAVE_INTERVAL_IN_EPOCHS * len(loaders['train'])\n",
        "\n",
        "\n",
        "# Show data in data loaders\n",
        "\n",
        "# Trainining samples\n",
        "show_batch(loaders['train'])\n",
        "\n",
        "# Validation samples \n",
        "show_batch(loaders['validation'])\n",
        "\n",
        "# Testing samples\n",
        "show_batch(loaders['test'])\n",
        "\n",
        "if os.path.exists(DATA_PATH):\n",
        "    !rm -r '/content/logs'\n",
        "\n",
        "if not os.path.exists(DATA_PATH):\n",
        "    os.mkdir(DATA_PATH)\n",
        "\n",
        "if not os.path.exists(MODEL_DIR_BASE):\n",
        "    os.mkdir(MODEL_DIR_BASE)\n",
        "\n",
        "if not os.path.exists(MODEL_DIR):\n",
        "    os.mkdir(MODEL_DIR)\n",
        "\n",
        "if not os.path.exists(TB_RUN_DIR_BASE):\n",
        "    os.mkdir(TB_RUN_DIR_BASE)\n",
        "\n",
        "if not os.path.exists(TB_RUN_DIR):\n",
        "    os.mkdir(TB_RUN_DIR)\n",
        "\n",
        "if GPU_DEVICE is not None:\n",
        "    torch.cuda.set_device(GPU_DEVICE)\n",
        "\n",
        "if MULTI_GPU:\n",
        "    batch_size *= torch.cuda.device_count()\n",
        "  \n",
        "# train_sets = []\n",
        "# train_loaders = []\n",
        "# THRESHOLD = 464\n",
        "\n",
        "# while True:\n",
        "#     if len(train_set) < THRESHOLD:\n",
        "#         train_loaders.append(torch.utils.data.DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS))\n",
        "#         break\n",
        "\n",
        "#     train_set, new_train_set_segment = random_split(train_set, [len(train_set) - THRESHOLD, THRESHOLD])\n",
        "#     train_loaders.append(torch.utils.data.DataLoader(new_train_set_segment, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS))\n",
        "# print(len(train_loaders))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Chx9gn06xHvb"
      },
      "outputs": [],
      "source": [
        "class Trainer:\n",
        "    \"\"\"\n",
        "    Wrapper object for handling training and evaluation\n",
        "    \"\"\"\n",
        "    def __init__(self, loaders, batch_size, learning_rate, lr_decay, device, multi_gpu):\n",
        "        self.tb = SummaryWriter(comment=TB_COMMENT, log_dir=TB_RUN_DIR)\n",
        "        self.device = device\n",
        "        self.multi_gpu = multi_gpu\n",
        "        self.all_preds = []\n",
        "        self.all_preds_list = []\n",
        "        self.all_labels = []\n",
        "        self.all_labels_list = []\n",
        "        self.all_confidences_list = []\n",
        "        self.incorrect_samples = []\n",
        "        self.incorrect_samples_targets = []\n",
        "\n",
        "        self.loaders = loaders\n",
        "        img_shape = self.loaders['train'].dataset[0][0].numpy().shape\n",
        "        \n",
        "        self.net = EfficientNet.from_pretrained('efficientnet-b3')\n",
        "        # self.net = torchvision.models.densenet161(pretrained=True)\n",
        "        # self.net = torchvision.models.resnet50(pretrained=True)\n",
        "        # self.net = torchvision.models.googlenet(pretrained=True)\n",
        "        # self.net = torchvision.models.mobilenet_v2(pretrained=True)\n",
        "        # self.net = torch.hub.load(repo, model_name, pretrained=True)\n",
        "        # self.net = torchvision.models.shufflenet_v2_x1_0(pretrained=False)\n",
        "        self.net = self.net.cuda()\n",
        "        \n",
        "        if self.multi_gpu:\n",
        "            self.net = nn.DataParallel(self.net)\n",
        "\n",
        "        self.optimizer = optim.Adam(self.net.parameters(), lr=learning_rate)\n",
        "        self.scheduler = optim.lr_scheduler.ExponentialLR(self.optimizer, gamma=lr_decay)\n",
        "        print(10*'#', 'PyTorch Model built'.upper(), 10*'#')\n",
        "        print('No. of params:', sum([np.prod(p.size()) for p in self.net.parameters()]))\n",
        "        print(TB_COMMENT)\n",
        "    \n",
        "    def __repr__(self):\n",
        "        return repr(self.net)\n",
        "\n",
        "    def run(self, epochs, classes):\n",
        "        print(8*'#', 'Run started'.upper(), 8*'#')\n",
        "        eye = torch.eye(len(classes)).to(self.device)\n",
        "        \n",
        "        epoch_time=time()\n",
        "        for epoch in range(1, epochs+1):\n",
        "            for phase in ['train', 'validation']:\n",
        "                if phase == 'train':\n",
        "                    self.net.train()\n",
        "                else:\n",
        "                    self.net.eval()\n",
        "\n",
        "                t0 = time()\n",
        "                running_loss = 0.0\n",
        "                running_margin_loss = 0.0\n",
        "                running_reconstruction_loss = 0.0\n",
        "                correct = 0; total = 0\n",
        "                batch_len = len(self.loaders[phase])\n",
        "\n",
        "                for i, (images, labels) in enumerate(self.loaders[phase]):\n",
        "                    n_iter = ((epoch-1) * batch_len) + i\n",
        "                    t1 = time()\n",
        "                    images, labels = images.to(self.device), labels.to(self.device)\n",
        "\n",
        "                    self.optimizer.zero_grad()\n",
        "\n",
        "                    preds = self.net(images) # reconstructions[ BATCH_SIZE, CHANNEL_NO, IMG_DIM, IMG_DIM]\n",
        "                    loss = F.cross_entropy(preds, labels) # Loss function\n",
        "\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        self.optimizer.step()\n",
        "\n",
        "                    running_loss += loss.item()\n",
        "\n",
        "                    total += labels.size(0)\n",
        "                    correct += get_num_correct(preds, labels)\n",
        "                    accuracy = float(correct) / float(total)\n",
        "\n",
        "                    if phase == 'train' and (n_iter % LOG_INTERVAL) == 0:\n",
        "                        print('-----------------------\\n', 'Epoch: ', epoch)\n",
        "\n",
        "                    if phase == 'train' and (n_iter % LR_UPDATE_INTERVAL_IN_ITERATIONS) == 0 and (n_iter != 0):\n",
        "                        self.scheduler.step()\n",
        "\n",
        "                    if phase == 'train' and (n_iter % MODEL_SAVE_INTERVAL_IN_ITERATIONS) == 0 and (n_iter != 0):\n",
        "                        torch.save(self.net.state_dict(), os.path.join(MODEL_DIR, str(n_iter)+'.pth.tar'))\n",
        "                    \n",
        "\n",
        "                print('{} \\t  Loss: {:.5f}  Accuracy: {:.5f}  Time: {:.3f}s'.format(phase.upper(), running_loss/(i+1), accuracy, time()-t0))\n",
        "                n_iter = epoch * batch_len\n",
        "                self.tb.add_scalar(f'{phase}/loss', running_loss/(i+1), n_iter)\n",
        "                self.tb.add_scalar(f'{phase}/accuracy', accuracy, n_iter)\n",
        "            print('Epoch Ended at: {}'.format(time()))\n",
        "            print('Epoch: {:02d} {:.3f}s elapsed'.format(epoch,time()-epoch_time)) \n",
        "        self.tb.close()\n",
        "            \n",
        "        now = str(datetime.now()).replace(\" \", \"-\")\n",
        "        error_rate = round((1-accuracy)*100, 2)\n",
        "        torch.save(self.net.state_dict(), os.path.join(MODEL_DIR, 'model.pth.tar'))\n",
        "\n",
        "    \n",
        "    def test(self, show_per_class_accuracy=False, show_incorrect_inferences=False):\n",
        "        self.net.eval()\n",
        "        self.all_preds = []\n",
        "        self.all_labels = []\n",
        "        self.incorrect_samples = []\n",
        "        self.incorrect_samples_idx = []\n",
        "        self.incorrect_samples_filename = []\n",
        "        self.incorrect_samples_targets = []\n",
        "        self.incorrect_samples_confidences = []\n",
        "        self.all_confidences = []\n",
        "        \n",
        "        eye = torch.eye(len(classes)).to(self.device)\n",
        "        t0 = time()\n",
        "        running_loss = 0.0\n",
        "        correct = 0; total = 0\n",
        "        batch_len = len(self.loaders['test'])\n",
        "        for i, (images, labels) in enumerate(self.loaders['test']):\n",
        "            t1 = time()\n",
        "            images, labels = images.to(self.device), labels.to(self.device)\n",
        "\n",
        "            self.optimizer.zero_grad()\n",
        "\n",
        "            preds = self.net(images)\n",
        "            confidences = []\n",
        "            confidence_list_for_epoch = []\n",
        "\n",
        "            for i in range(len(preds)):\n",
        "                confidence = (torch.nn.functional.softmax(preds[i][:2], dim=0))[0].item()\n",
        "                self.all_confidences.append(confidence)\n",
        "\n",
        "            loss = F.cross_entropy(preds, labels) # Loss function\n",
        "\n",
        "            if show_incorrect_inferences:\n",
        "                incorrect_idxes = torch.nonzero((preds.argmax(dim=1).eq(labels)==False))\n",
        "\n",
        "                for incorrect_idx in incorrect_idxes:\n",
        "                    idx = incorrect_idx.item()\n",
        "                    self.incorrect_samples.append(images[idx])\n",
        "                    relative_idx = (i*BATCH_SIZE + idx) if labels[idx].item()==0 else ((i*BATCH_SIZE + idx)-len(test_set_filenames[0]))\n",
        "                    self.incorrect_samples_idx.append(relative_idx)\n",
        "                    class_name = 'glaucoma' if labels[idx].item()==0 else 'normal'\n",
        "                    self.incorrect_samples_filename.append( class_name + '/' + test_set_filenames[labels[idx].item()][relative_idx])\n",
        "                    self.incorrect_samples_targets.append(labels[idx].item())\n",
        "                    confidence = (torch.nn.functional.softmax(preds[incorrect_idx][:2], dim=1))[0][ preds[incorrect_idx].argmax(dim=1).item() ].item()\n",
        "                    self.incorrect_samples_confidences.append(confidence)\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            total += labels.size(0)\n",
        "            correct += get_num_correct(preds, labels)\n",
        "            accuracy = float(correct) / float(total)\n",
        "            self.all_labels = np.append(self.all_labels, labels.cpu().numpy())\n",
        "            self.all_preds = np.append(self.all_preds, preds.argmax(dim=1).cpu().numpy())\n",
        "\n",
        "        self.all_labels_list.append(self.all_labels)\n",
        "        self.all_preds_list.append(self.all_preds)\n",
        "        self.all_confidences_list.append(self.all_confidences)\n",
        "        \n",
        "        print('{} \\tLoss: {:.5f}   Accuracy: {:.5f}  Time: {:.3f}s ------ Test Accuracy: {:.5f}'.format( #22\n",
        "            'TEST', \n",
        "            running_loss/(i+1), \n",
        "            accuracy, \n",
        "            time()-t0,\n",
        "            accuracy\n",
        "            )) #22\n",
        "            \n",
        "        now = str(datetime.now()).replace(\" \", \"-\")\n",
        "        error_rate = round((1-accuracy)*100, 2)\n",
        "\n",
        "        if show_per_class_accuracy:\n",
        "            class_correct = list(0. for _ in classes)\n",
        "            class_total = list(0. for _ in classes)\n",
        "            for images, labels in self.loaders['test']:\n",
        "                images, labels = images.to(self.device), labels.to(self.device)\n",
        "\n",
        "                preds = self.net(images)\n",
        "                preds = preds.argmax(dim=1)\n",
        "                for i in range(labels.size(0)):\n",
        "                    label = labels[i]\n",
        "                    if labels[i] == preds[i]:\n",
        "                            class_correct[label] += 1\n",
        "                    class_total[label] += 1\n",
        "                        \n",
        "            print('\\nPer class accuracy on TEST set:')\n",
        "            for i in range(len(classes)):\n",
        "                print('Accuracy of {} ({}) : {:.2f}%     ({:5d}/{:5d})'.format(classes[i], i, 100 * class_correct[i] / class_total[i], int(class_correct[i]), int(class_total[i])))\n",
        "\n",
        "    def show_incorrect_prediction(self):\n",
        "        print('\\nIncorrect samples\\' corrrect labels: ', self.incorrect_samples_targets)\n",
        "        print('\\nIncorrect samples\\' confidences: ', self.incorrect_samples_confidences)\n",
        "        print('\\nIncorrect samples\\' idxes: ', self.incorrect_samples_idx)\n",
        "        print('\\nIncorrect samples\\' filenames (', len(self.incorrect_samples_filename), ') : ', self.incorrect_samples_filename)\n",
        "        print('Incorrectly predicted samples:')\n",
        "        fig, ax = plt.subplots(figsize=(25, 25))\n",
        "        ax.set_xticks([]); ax.set_yticks([])\n",
        "        img_grid = torchvision.utils.make_grid(self.incorrect_samples, nrow=10, normalize=True)\n",
        "        _ = ax.imshow(make_grid(img_grid.cpu().detach().permute(1, 2, 0)))\n",
        "\n",
        "    def show_classification_report(self, epoch, target_names=classes):\n",
        "        all_preds = self.all_preds_list[epoch]\n",
        "        print(classification_report(self.all_labels, all_preds, target_names=target_names, digits=4))\n",
        "\n",
        "    def show_confusion_matrix(self, epoch=0, xticklabels=classes, yticklabels=classes, ):\n",
        "        all_labels = self.all_labels_list[epoch]\n",
        "        all_preds = self.all_preds_list[epoch]\n",
        "        confusion_matrix_test = confusion_matrix(all_labels, all_preds, labels = None, sample_weight = None, normalize = None)\n",
        "        heatmap_test = sn.heatmap(confusion_matrix_test, annot=True)\n",
        "        _ = heatmap_test.set(xlabel='Predicted label', ylabel='Actual label', xticklabels=xticklabels, yticklabels=yticklabels)\n",
        "    \n",
        "    def saveData(self, G_DRIVE_DIR=''):\n",
        "        if D_DRIVE_DIR != '':\n",
        "            try:\n",
        "                if not os.path.exists(G_DRIVE_DIR):\n",
        "                    os.mkdir(G_DRIVE_DIR)\n",
        "                    os.mkdir(G_DRIVE_DIR+'/models')\n",
        "                    os.mkdir(G_DRIVE_DIR+'/runs')\n",
        "            except:\n",
        "                print('ERROR: G_DRIVE_DIR dir creation error')\n",
        "\n",
        "            try:\n",
        "                dest = shutil.move( MODEL_DIR, os.path.join(G_DRIVE_DIR, 'models'))\n",
        "                print(\"Transfered to: \", dest)\n",
        "            except:\n",
        "                print('ERROR: G_DRIVE_DIR model transfer error')\n",
        "\n",
        "            try:\n",
        "                dest = shutil.move( TB_RUN_DIR, os.path.join(G_DRIVE_DIR, 'runs'))\n",
        "                print(\"Transfered to: \", dest)\n",
        "            except:\n",
        "                print('ERROR: G_DRIVE_DIR runs transfer error')\n",
        "\n",
        "    def load(self, load_path):\n",
        "        if load_path != None:\n",
        "            try:\n",
        "                self.net.load_state_dict(torch.load(load_path))\n",
        "                _ = self.net.eval()\n",
        "                print('Model state loaded')\n",
        "            except Exception as e: \n",
        "                print('ERROR: Model state load error: ', e)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "294db3686d984ed69e1c166f8111c341",
            "5ac35d2bdf7448289915b8cff1807df8",
            "a416bedb86ca44c98f2cbae5854c5db5",
            "02fd7105c77e4f4686caf7dcb2edd570",
            "546a8718410e4d6c8a26a81d711d0081",
            "70285d82ba85400a92f6dfbab5a46ded",
            "220c4fb6560344adaa976fe325b0f1fb",
            "2813a5890ec84f21a451fd323df1e196",
            "e33654a976a1460a825e3935eabbaf56",
            "618ed3d7e98a44a88df86e219f7330bb",
            "ff2d48248a8641e595a672b96fc81492"
          ]
        },
        "id": "YYSHlLnX29rD",
        "outputId": "1c7ba38d-47f7-45b1-902e-5e78dc74c51b"
      },
      "outputs": [],
      "source": [
        "# Train Model\n",
        "EPOCHS = 70\n",
        "LEARNING_RATE = 0.001\n",
        "\n",
        "TB_COMMENT = f'Network {DATASET} batch_size={BATCH_SIZE} lr={LEARNING_RATE} lr_decay={LR_DECAY} E={EPOCHS}'\n",
        "print(TB_COMMENT)\n",
        "\n",
        "\n",
        "net_trainer = Trainer(loaders, BATCH_SIZE, LEARNING_RATE, LR_DECAY, device=DEVICE, multi_gpu=MULTI_GPU)\n",
        "# net_trainer.load(load_path = None)\n",
        "net_trainer.run(EPOCHS, classes=classes)\n",
        "# net_trainer.saveData('/content/BEH_Net')\n",
        "try:\n",
        "  net_trainer.test(show_per_class_accuracy=True, show_incorrect_inferences=False)\n",
        "except Exception as e:\n",
        "  print(\"Exception \", e)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 514
        },
        "id": "mqorxbRIccBr",
        "outputId": "cb395c12-5abe-4f14-c1fa-29e12deaef21"
      },
      "outputs": [],
      "source": [
        "EPOCH = 62\n",
        "\n",
        "net_trainer.show_classification_report(epoch=EPOCH-1)\n",
        "\n",
        "roc_auc = roc_auc_score(net_trainer.all_labels_list[EPOCH-1], net_trainer.all_preds_list[EPOCH-1])\n",
        "print('ROC AUC Score: {:.4f}'.format(roc_auc))\n",
        "\n",
        "print('\\n\\nConfusion matrix:')\n",
        "net_trainer.show_confusion_matrix(epoch = EPOCH-1)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "ORIGA_Shafin.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "02fd7105c77e4f4686caf7dcb2edd570": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e33654a976a1460a825e3935eabbaf56",
            "max": 49388949,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2813a5890ec84f21a451fd323df1e196",
            "value": 49388949
          }
        },
        "220c4fb6560344adaa976fe325b0f1fb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2813a5890ec84f21a451fd323df1e196": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "294db3686d984ed69e1c166f8111c341": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a416bedb86ca44c98f2cbae5854c5db5",
              "IPY_MODEL_02fd7105c77e4f4686caf7dcb2edd570",
              "IPY_MODEL_546a8718410e4d6c8a26a81d711d0081"
            ],
            "layout": "IPY_MODEL_5ac35d2bdf7448289915b8cff1807df8"
          }
        },
        "546a8718410e4d6c8a26a81d711d0081": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ff2d48248a8641e595a672b96fc81492",
            "placeholder": "​",
            "style": "IPY_MODEL_618ed3d7e98a44a88df86e219f7330bb",
            "value": " 47.1M/47.1M [00:00&lt;00:00, 98.2MB/s]"
          }
        },
        "5ac35d2bdf7448289915b8cff1807df8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "618ed3d7e98a44a88df86e219f7330bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "70285d82ba85400a92f6dfbab5a46ded": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a416bedb86ca44c98f2cbae5854c5db5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_220c4fb6560344adaa976fe325b0f1fb",
            "placeholder": "​",
            "style": "IPY_MODEL_70285d82ba85400a92f6dfbab5a46ded",
            "value": "100%"
          }
        },
        "e33654a976a1460a825e3935eabbaf56": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ff2d48248a8641e595a672b96fc81492": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
